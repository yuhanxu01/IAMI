# IAMI GraphRAG Environment Variables

# ============================================
# LLM Provider Configuration
# ============================================

# 选择LLM提供者: "deepseek", "glm", "openai"
LLM_PROVIDER=deepseek  # 默认使用DeepSeek

# DeepSeek API Key
DEEPSEEK_API_KEY=your_deepseek_api_key_here
# Optional: Override default DeepSeek settings
# DEEPSEEK_API_BASE=https://api.deepseek.com/v1
# DEEPSEEK_MODEL=deepseek-chat

# GLM-4 (智谱AI) API Key
# GLM_API_KEY=your_glm_api_key_here
# Optional: Override default GLM settings
# GLM_API_BASE=https://open.bigmodel.cn/api/paas/v4
# GLM_MODEL=glm-4.7  # 可选: glm-4.7, glm-4, glm-4-plus, glm-4-air, glm-4-flash
# GLM_EMBEDDING_MODEL=embedding-2

# OpenAI API Key
# OPENAI_API_KEY=your_openai_key
# Optional: Override default OpenAI settings
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o

# ============================================
# 通用LLM配置 (适用于所有提供者)
# ============================================
# LLM_TEMPERATURE=0.7
# LLM_MAX_TOKENS=4000

# 超时配置（秒）
# LLM_TIMEOUT=30.0
# LLM_REQUEST_TIMEOUT=30.0

# 重试配置
# LLM_MAX_RETRIES=3
# LLM_RETRY_WAIT_MIN=1.0
# LLM_RETRY_WAIT_MAX=10.0

# 并发限制
# LLM_MAX_CONCURRENT=5  # 同时进行的最大API调用数

# 速率限制
# LLM_MAX_CALLS_PER_MINUTE=20  # 每分钟最大API调用数

# ============================================
# Storage Paths (Optional - defaults in config.yaml)
# ============================================
# GRAPHRAG_INDEX_DIR=./graphrag/storage/index
# GRAPHRAG_CACHE_DIR=./graphrag/storage/cache

# ============================================
# MCP Server Configuration
# ============================================
# MCP_PORT=3000
# MCP_HOST=localhost

# ============================================
# Logging
# ============================================
LOG_LEVEL=INFO
