"""
æ¨¡æ‹Ÿæ¨¡å¼é¡µé¢

åŠŸèƒ½ï¼š
1. ä»¥ç”¨æˆ·æ€ç»´æ¨¡å¼å›ç­”é—®é¢˜
2. æ˜¾ç¤ºä½¿ç”¨çš„è®°å¿†ä¸Šä¸‹æ–‡
3. æµ‹è¯• AI å¯¹ç”¨æˆ·çš„ç†è§£ç¨‹åº¦
"""

import asyncio
import streamlit as st
from datetime import datetime


def render():
    """æ¸²æŸ“æ¨¡æ‹Ÿæ¨¡å¼é¡µé¢"""
    st.markdown("# ğŸ’¬ æ¨¡æ‹Ÿæ¨¡å¼")
    st.markdown("AI å°†ä»¥**ä½ çš„æ€ç»´æ¨¡å¼**å›ç­”é—®é¢˜")
    st.markdown("---")

    # æ£€æŸ¥ä»£ç†
    if not st.session_state.agents_loaded:
        st.error("ä»£ç†æœªåŠ è½½")
        return

    agent = st.session_state.simulation_agent

    # è®¾ç½®åŒºåŸŸ
    with st.sidebar:
        st.markdown("### âš™ï¸ æ¨¡æ‹Ÿè®¾ç½®")

        use_latest_only = st.checkbox(
            "åªä½¿ç”¨æœ€æ–°è®°å¿†",
            value=True,
            help="è€ƒè™‘æ€æƒ³æ¼”å˜ï¼Œåªä½¿ç”¨æœ€è¿‘çš„è®°å¿†å¿«ç…§"
        )

        st.markdown("---")
        st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
        st.info("""
        - é—®ä¸€äº›ä½ å¯èƒ½è¢«é—®åˆ°çš„é—®é¢˜
        - æµ‹è¯• AI æ˜¯å¦ç†è§£ä½ çš„ç«‹åœº
        - çœ‹çœ‹ AI èƒ½å¦ç”¨ä½ çš„æ–¹å¼æ€è€ƒ
        """)

    # èŠå¤©åŒºåŸŸ
    st.markdown("### ğŸ’¬ å¯¹è¯")

    # åˆå§‹åŒ–èŠå¤©å†å²
    if "simulation_messages" not in st.session_state:
        st.session_state.simulation_messages = []

    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.simulation_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # æ˜¾ç¤ºå…ƒæ•°æ®
            if message["role"] == "assistant" and "metadata" in message:
                with st.expander("æŸ¥çœ‹ç”Ÿæˆè¯¦æƒ…"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ä½¿ç”¨çš„è®°å¿†", message["metadata"].get("memories_used", 0))
                    with col2:
                        st.metric("æ£€ç´¢ä¸Šä¸‹æ–‡", f"{message['metadata'].get('retrieval_context_length', 0)} å­—ç¬¦")

                    if "profile_summary" in message["metadata"]:
                        st.markdown("**äººç‰©ç”»åƒæ‘˜è¦**")
                        st.markdown(message["metadata"]["profile_summary"])

    # è¾“å…¥åŒºåŸŸ
    if prompt := st.chat_input("é—®æˆ‘ä»»ä½•é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.simulation_messages.append({
            "role": "user",
            "content": prompt
        })

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)

        # ç”Ÿæˆæ¨¡æ‹Ÿå›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨ä»¥ä½ çš„æ€ç»´æ€è€ƒ..."):
                try:
                    result = asyncio.run(agent.simulate_response(
                        query=prompt,
                        use_latest_only=use_latest_only
                    ))

                    response_text = result.get("simulated_response", "")

                    # æ˜¾ç¤ºå›ç­”
                    st.markdown(response_text)

                    # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
                    st.session_state.simulation_messages.append({
                        "role": "assistant",
                        "content": response_text,
                        "metadata": result
                    })

                    # æ˜¾ç¤ºè¯¦æƒ…
                    with st.expander("æŸ¥çœ‹ç”Ÿæˆè¯¦æƒ…"):
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ä½¿ç”¨çš„è®°å¿†", result.get("memories_used", 0))
                        with col2:
                            st.metric("æ£€ç´¢ä¸Šä¸‹æ–‡", f"{result.get('retrieval_context_length', 0)} å­—ç¬¦")

                        if result.get("profile_summary"):
                            st.markdown("**äººç‰©ç”»åƒæ‘˜è¦**")
                            st.markdown(result["profile_summary"])

                except Exception as e:
                    st.error(f"ç”Ÿæˆå›ç­”å¤±è´¥: {e}")
                    import traceback
                    st.code(traceback.format_exc())

    # æ§åˆ¶æŒ‰é’®
    st.markdown("---")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯", use_container_width=True):
            st.session_state.simulation_messages = []
            st.rerun()

    with col2:
        if st.button("ğŸ’¾ å¯¼å‡ºå¯¹è¯", use_container_width=True):
            if st.session_state.simulation_messages:
                # è½¬æ¢ä¸ºæ–‡æœ¬
                export_text = "# IAMI æ¨¡æ‹Ÿå¯¹è¯\n\n"
                export_text += f"å¯¼å‡ºæ—¶é—´: {datetime.now().isoformat()}\n\n"
                export_text += "---\n\n"

                for msg in st.session_state.simulation_messages:
                    role = "ğŸ‘¤ ç”¨æˆ·" if msg["role"] == "user" else "ğŸ¤– AI (æ¨¡æ‹Ÿä½ )"
                    export_text += f"## {role}\n\n{msg['content']}\n\n"

                st.download_button(
                    label="ä¸‹è½½å¯¹è¯",
                    data=export_text,
                    file_name=f"simulation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown"
                )
            else:
                st.warning("æ²¡æœ‰å¯¹è¯å¯å¯¼å‡º")

    with col3:
        if st.button("ğŸ“Š ç”Ÿæˆè¯„ä¼°", use_container_width=True):
            if st.session_state.simulation_messages:
                st.info("æ­¤åŠŸèƒ½å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­æä¾›ï¼šå¯¹æ¨¡æ‹Ÿè´¨é‡è¿›è¡Œè¯„ä¼°")
            else:
                st.warning("éœ€è¦å…ˆè¿›è¡Œå¯¹è¯")

    # æµ‹è¯•å»ºè®®
    st.markdown("---")
    st.markdown("### ğŸ’¡ æµ‹è¯•å»ºè®®")

    test_questions = [
        "ä½ å¯¹äººå·¥æ™ºèƒ½çš„çœ‹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å¦‚æœå¿…é¡»åœ¨åˆ›æ–°å’Œç¨³å®šä¹‹é—´é€‰æ‹©ï¼Œä½ ä¼šé€‰å“ªä¸ªï¼Ÿ",
        "ä½ é€šå¸¸å¦‚ä½•åšé‡è¦å†³å®šï¼Ÿ",
        "ä½ æœ€é‡è§†çš„å“è´¨æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ä½ å¯¹å·¥ä½œå’Œç”Ÿæ´»å¹³è¡¡æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿ"
    ]

    st.markdown("å°è¯•é—®è¿™äº›é—®é¢˜ï¼š")
    cols = st.columns(2)
    for idx, question in enumerate(test_questions):
        col = cols[idx % 2]
        with col:
            if st.button(f"ğŸ“ {question}", key=f"test_q_{idx}"):
                st.session_state.test_question = question
                # è§¦å‘é—®é¢˜è¾“å…¥
                st.rerun()
