"""
å­¦ä¹ æ¨¡å¼é¡µé¢ (Async Version)

åŠŸèƒ½ï¼š
1. å¼‚æ­¥ç”Ÿæˆé—®é¢˜ï¼ˆé¢„åŠ è½½ï¼‰
2. åå°åˆ†æå›ç­”ï¼ˆéé˜»å¡ï¼‰
3. æµç•…çš„ç”¨æˆ·ä½“éªŒ
"""

import asyncio
import streamlit as st
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Dict, Any, List

# --- Helper Functions for Background Tasks ---

def run_background_analysis(agent, question: Dict[str, Any], answer: str):
    """
    åå°è¿è¡Œåˆ†æå’Œæ›´æ–°ä»»åŠ¡
    """
    try:
        # Create a new event loop for this thread if needed
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # 1. Analyze
        analysis = loop.run_until_complete(agent.analyze_answer(question, answer))
        
        # 2. Update Memory
        loop.run_until_complete(agent.update_memory(analysis, answer))
        
        loop.close()
        return analysis
    except Exception as e:
        print(f"Background analysis failed: {e}")
        return None

def run_background_generation(agent, category: Optional[str], context: Optional[str], question_type: str, excluded_questions: List[str]):
    """
    åå°ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜
    """
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        question = loop.run_until_complete(agent.generate_question(
            category=category,
            context=context,
            question_type=question_type,
            excluded_questions=excluded_questions
        ))
        
        loop.close()
        return question
    except Exception as e:
        print(f"Background generation failed: {e}")
        return None

@st.cache_resource
def get_executor():
    """å…¨å±€çº¿ç¨‹æ± """
    return ThreadPoolExecutor(max_workers=2)

def render():
    """æ¸²æŸ“å­¦ä¹ æ¨¡å¼é¡µé¢"""
    st.markdown("# â—‡ å­¦ä¹ æ¨¡å¼")
    st.markdown("é€šè¿‡å¯¹è¯äº†è§£æ‚¨çš„æ€ç»´æ¨¡å¼ã€ä»·å€¼è§‚å’Œæ€§æ ¼ç‰¹å¾")
    st.markdown("---")

    # æ£€æŸ¥ä»£ç†
    if not st.session_state.agents_loaded:
        st.error("ä»£ç†æœªåŠ è½½")
        return

    agent = st.session_state.learning_agent
    executor = get_executor()

    # --- State Management ---
    
    if "current_question" not in st.session_state:
        st.session_state.current_question = None
        
    if "next_question_future" not in st.session_state:
        st.session_state.next_question_future = None
        
    if "analysis_futures" not in st.session_state:
        st.session_state.analysis_futures = []
        
    if "question_type_choice" not in st.session_state:
        st.session_state.question_type_choice = "open"

    if "feedback_message" not in st.session_state:
        st.session_state.feedback_message = None

    # --- UI Components ---

    # æ˜¾ç¤ºå­¦ä¹ è¿›åº¦
    with st.expander("â—ˆ å­¦ä¹ è¿›åº¦", expanded=False):
        try:
            stats = asyncio.run(agent.get_learning_stats())
            col1, col2 = st.columns(2)
            with col1:
                st.metric("å·²å›ç­”é—®é¢˜", stats.get("total_questions", 0))
                st.metric("å®Œæˆåº¦", f"{stats.get('completion_rate', 0):.1f}%")
            with col2:
                breakdown = stats.get("category_breakdown", {})
                st.markdown("**ç±»åˆ«åˆ†å¸ƒ**")
                for cat, data in breakdown.items():
                    st.write(f"- {cat}: {data.get('count', 0)}")
        except Exception:
             st.write("åŠ è½½ä¸­...")

    # åé¦ˆæ¶ˆæ¯ (Toast-like)
    if st.session_state.feedback_message:
        st.success(st.session_state.feedback_message)
        st.session_state.feedback_message = None # Show once

    st.markdown("---")

    # è‡ªå®šä¹‰ CSS ç”¨äºæœ¬é¡µ
    st.markdown("""
<style>
    @media (max-width: 768px) {
        .question-card {
            padding: 1.2rem !important;
            margin: 1rem 0 !important;
        }
        .question-card h3 {
            font-size: 1.2rem !important;
        }
    }
</style>
""", unsafe_allow_html=True)

    col1, col2 = st.columns([2, 1])

    # åœ¨æ‰‹æœºç«¯ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›è®¾ç½®åœ¨ä¸‹é¢æˆ–è€…åœ¨æŠ˜å é¢æ¿é‡Œ
    with col2:
        with st.expander("âš™ï¸ è®¾ç½®", expanded=st.session_state.get("mobile_settings_expanded", False)):
            st.markdown("### â—‡ é—®é¢˜è®¾ç½®")
            
            # ç±»åˆ«é€‰æ‹©
            category_options = {
                "è‡ªåŠ¨é€‰æ‹©": None,
                "æ€§æ ¼ç‰¹å¾": "personality",
                "ä»·å€¼è§‚": "values",
                "æ€ç»´æ¨¡å¼": "thinking_patterns",
                "é“å¾·åŸºç¡€": "moral_foundations",
                "äººé™…å…³ç³»": "relationships",
                "ç¯å¢ƒç³»ç»Ÿ": "environment",
                "è¯­è¨€é£æ ¼": "language_style",
                "ç¤¾ä¼šçƒ­ç‚¹": "social_hotspots"
            }
            selected_cat_name = st.selectbox("é—®é¢˜ç±»åˆ«", list(category_options.keys()))
            selected_category = category_options[selected_cat_name]

            # é—®é¢˜ç±»å‹é€‰æ‹©
            st.markdown("### é—®é¢˜ç±»å‹")
            c1, c2 = st.columns(2)
            with c1:
                if st.button("é—®ç­”é¢˜", type="primary" if st.session_state.question_type_choice == "open" else "secondary", use_container_width=True):
                    st.session_state.question_type_choice = "open"
                    
            with c2:
                if st.button("é€‰æ‹©é¢˜", type="primary" if st.session_state.question_type_choice == "mcq" else "secondary", use_container_width=True):
                    st.session_state.question_type_choice = "mcq"

            # é¢å¤–ä¸Šä¸‹æ–‡
            context = st.text_area("é¢å¤–ä¸Šä¸‹æ–‡", placeholder="æŒ‡å¯¼é—®é¢˜ç”Ÿæˆ...", height=68)

            # å¼ºåˆ¶ç”ŸæˆæŒ‰é’®
            if st.button("ç”Ÿæˆæ–°é—®é¢˜", use_container_width=True):
                st.session_state.next_question_future = None # Cancel pending
                st.session_state.current_question = None     # Clear current
                st.rerun() # Will trigger generation below

    with col1:
        st.markdown("### â—‡ å¯¹è¯åŒºåŸŸ")

        # --- Logic Flow ---

        # 1. Check if we need to fetch a question
        if st.session_state.current_question is None:
            if st.session_state.next_question_future is None:
                # Start generating Q1
                with st.spinner("æ­£åœ¨ç”Ÿæˆç¬¬ä¸€ä¸ªé—®é¢˜..."):
                    # We run this synchronously for the VERY first question to avoid blank screen
                    q = asyncio.run(agent.generate_question(
                        category=selected_category,
                        context=context,
                        question_type=st.session_state.question_type_choice
                    ))
                    st.session_state.current_question = q
                    st.rerun()
            else:
                # We have a future, check if it's done
                if st.session_state.next_question_future.done():
                    st.session_state.current_question = st.session_state.next_question_future.result()
                    st.session_state.next_question_future = None # Consumed
                    st.rerun()
                else:
                    with st.spinner("æ­£åœ¨å‡†å¤‡ä¸‹ä¸€ä¸ªé—®é¢˜..."):
                        # Wait for it
                        st.session_state.current_question = st.session_state.next_question_future.result()
                        st.session_state.next_question_future = None
                        st.rerun()
        
        # 2. Display Question
        if st.session_state.current_question:
            q_data = st.session_state.current_question
            
            # --- Pre-fetch Trigger ---
            # If we have a current question, but no NEXT question is being generated, start generating it NOW.
            if st.session_state.next_question_future is None:
                # æ’é™¤å½“å‰é—®é¢˜ä»¥åŠæœ¬æ¬¡ä¼šè¯ä¸­æ‰€æœ‰å·²å›ç­”/æ­£åœ¨å›ç­”çš„é—®é¢˜ï¼Œé¿å…å¹¶å‘å¯¼è‡´é‡å¤
                excluded = [q_data.get("question", "")]
                if "learning_history" in st.session_state:
                    for item in st.session_state.learning_history:
                        q_text = item.get("question", {}).get("question")
                        if q_text and q_text not in excluded:
                            excluded.append(q_text)
                            
                st.session_state.next_question_future = executor.submit(
                    run_background_generation,
                    agent, 
                    selected_category, # Use current settings for next Q
                    context,
                    st.session_state.question_type_choice,
                    excluded
                )
            
            # Render Card
            card_html = f"""
            <div class="question-card">
                <div style="font-size: 0.9rem; opacity: 0.8; margin-bottom: 0.5rem;">
                    <strong>é—®é¢˜</strong> (ç±»åˆ«: {q_data.get('category', 'unknown')})
                </div>
                <h3 style="margin: 0; line_height: 1.4;">{q_data.get('question', '')}</h3>
            </div>
            """
            st.markdown(card_html, unsafe_allow_html=True)

            if q_data.get("reasoning"):
                with st.expander("AI çš„æ€è€ƒ"):
                    st.write(q_data.get("reasoning"))

            # Input Area
            is_mcq = q_data.get("type") == "mcq"
            final_answer = ""
            submit_ready = False

            if is_mcq:
                opts = q_data.get("options", [])
                sel = st.radio("é€‰æ‹©å›ç­”:", opts, index=None, key=f"radio_{q_data.get('id')}")
                extra = st.text_area("è¡¥å……è¯´æ˜ (å¯é€‰):", key=f"text_{q_data.get('id')}")
                if sel:
                    final_answer = f"ç”¨æˆ·é€‰æ‹©äº†ï¼š{sel}ã€‚è¡¥å……è¯´æ˜ï¼š{extra}"
                    submit_ready = True
            else:
                final_answer = st.text_area("ä½ çš„å›ç­”:", height=200, key=f"text_{q_data.get('id')}")
                submit_ready = bool(final_answer.strip())

            # Action Buttons
            c_sub, c_skip = st.columns([1, 1])
            
            with c_sub:
                if st.button("æäº¤å›ç­”", type="primary", use_container_width=True, disabled=not submit_ready):
                    # 1. Add to history first to get index
                    history_item = {
                        "question": q_data,
                        "answer": final_answer,
                        "timestamp": datetime.now().isoformat(),
                        "status": "running",
                        "analysis": None
                    }
                    st.session_state.learning_history.append(history_item)
                    idx = len(st.session_state.learning_history) - 1
                    
                    # 2. Submit task with index reference
                    future = executor.submit(run_background_analysis, agent, q_data, final_answer)
                    st.session_state.analysis_futures.append((future, idx))
                    
                    # 3. Move to next question immediately
                    st.session_state.current_question = None 
                    st.session_state.feedback_message = "å›ç­”å·²æäº¤ï¼Œæ­£åœ¨åå°åˆ†æ..."
                    st.rerun()

            with c_skip:
                if st.button("è·³è¿‡", use_container_width=True):
                    st.session_state.current_question = None
                    st.rerun()

    # --- Analysis Status & History Update ---
    
    # Check for completed analyses
    # We use a list to store indices to remove
    indices_to_remove = []
    
    for i, (future, hist_idx) in enumerate(st.session_state.analysis_futures):
        if future.done():
            indices_to_remove.append(i)
            try:
                result = future.result()
                # Update the specific history item
                # Safety check: ensure index still valid (though list only appends)
                if 0 <= hist_idx < len(st.session_state.learning_history):
                    st.session_state.learning_history[hist_idx]["analysis"] = result
                    st.session_state.learning_history[hist_idx]["status"] = "completed"
                    
                    # Optional: Toast notification
                    # st.toast(f"é—®é¢˜ '{st.session_state.learning_history[hist_idx]['question']['question'][:10]}...' åˆ†æå®Œæˆ")
            except Exception as e:
                print(f"Error retrieving analysis result: {e}")

    # Remove processed futures (reverse order)
    for i in reversed(indices_to_remove):
        st.session_state.analysis_futures.pop(i)

    # --- Global History Display ---
    st.markdown("---")
    with st.expander("âŒ› å†å²è®°å½• (æŸ¥çœ‹æ‰€æœ‰å·²å›å¤é—®é¢˜)", expanded=False):
        try:
            full_history = asyncio.run(agent.get_full_history())
            if not full_history:
                st.info("æš‚æ— å†å²è®°å½•")
            else:
                # æŒ‰æ—¶é—´å€’åº
                for item in reversed(full_history):
                    # å…¼å®¹æ€§å¤„ç†ï¼šå°è¯•æ–°å­—æ®µåï¼Œå›é€€åˆ°æ—§å­—æ®µå
                    q_text = item.get("question_text") or item.get("question", "æœªçŸ¥é—®é¢˜")
                    ans_text = item.get("answer", "æœªè®°å½•å›ç­”")
                    timestamp = item.get("timestamp", "")[:16].replace("T", " ")
                    cat = item.get("category", "unknown")
                    
                    with st.expander(f"ğŸ“… {timestamp} | {q_text[:30]}...", expanded=False):
                        st.markdown(f"**é—®é¢˜**: {q_text}")
                        st.markdown(f"**ç±»åˆ«**: {cat}")
                        st.markdown(f"**å›ç­”**: {ans_text}")
                        
                        # ä¼˜å…ˆå±•ç¤ºè¯¦ç»†åˆ†æç»“æœï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•å±•ç¤º summary
                        analysis_results = item.get('analysis_results', [])
                        if analysis_results:
                            st.markdown("#### åˆ†æç»“æœ")
                            for f in analysis_results:
                                st.write(f"- **{f.get('trait')}**: {f.get('value')} (ç½®ä¿¡åº¦: {f.get('confidence')}/5)")
                        elif item.get('analysis_summary'):
                            summary = item['analysis_summary']
                            st.markdown("#### åˆ†ææ‘˜è¦")
                            st.write(f"- ç‰¹å¾æ•°é‡: {summary.get('features_count', 0)}")
                            st.write(f"- å¹³å‡ç½®ä¿¡åº¦: {summary.get('confidence_avg', 0):.1f}/5")
                        else:
                            st.info("è¯¥æ¡è®°å½•æš‚æ— è¯¦ç»†åˆ†æç»“æœ")
                        
                        # åˆ é™¤æŒ‰é’®
                        if st.button("ğŸ—‘ï¸ åˆ é™¤è¯¥æ¡è®°å½•", key=f"del_{item.get('timestamp')}", use_container_width=True):
                            if asyncio.run(agent.delete_history_item(item.get('timestamp'))):
                                st.toast("è®°å½•å·²æˆåŠŸåˆ é™¤")
                                st.rerun()
                            else:
                                st.error("åˆ é™¤è®°å½•å¤±è´¥")
        except Exception as e:
            st.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")

    # --- History Display (Current Session) ---
    if st.session_state.learning_history:
        st.markdown("---")
        st.markdown("### â—‡ æœ¬æ¬¡ä¼šè¯å†å²")
        
        # Reverse to show newest first
        for item in reversed(st.session_state.learning_history):
            q_text = item['question'].get('question', '')
            status = item.get('status', 'completed')
            
            with st.expander(f"{'ğŸ”„' if status == 'running' else 'âœ…'} {q_text}", expanded=False):
                st.write(f"**æ‚¨çš„å›ç­”**: {item.get('answer')}")
                
                if status == 'running':
                    st.info("æ­£åœ¨åå°åˆ†æä¸­...")
                elif item.get('analysis'):
                    analysis = item['analysis']
                    st.markdown("#### åˆ†æç»“æœ")
                    features = analysis.get("features", [])
                    if features:
                        for f in features:
                            st.write(f"- **{f.get('trait')}**: {f.get('value')} (ç½®ä¿¡åº¦: {f.get('confidence')}/5)")
                    else:
                        st.write("æœªæå–åˆ°æ˜¾è‘—ç‰¹å¾")
                else:
                    st.warning("åˆ†ææœªèƒ½å®Œæˆ")

