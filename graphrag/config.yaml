# IAMI GraphRAG Configuration

# LLM Configuration
# 支持的提供者: deepseek, glm, openai
llm:
  provider: "deepseek"  # 默认使用DeepSeek（可选: "deepseek", "glm", "openai"）

  # DeepSeek 配置
  deepseek:
    api_key_env: "DEEPSEEK_API_KEY"
    base_url: "https://api.deepseek.com/v1"
    model: "deepseek-chat"
    embedding_model: "text-embedding-3-small"
    dimension: 1536

  # GLM-4 (智谱AI) 配置
  glm:
    api_key_env: "GLM_API_KEY"
    base_url: "https://open.bigmodel.cn/api/paas/v4"
    model: "glm-4.7"  # 或 "glm-4", "glm-4-plus", "glm-4-air", "glm-4-flash"
    embedding_model: "embedding-2"
    dimension: 1024

  # OpenAI 配置
  openai:
    api_key_env: "OPENAI_API_KEY"
    base_url: "https://api.openai.com/v1"
    model: "gpt-4o"
    embedding_model: "text-embedding-3-small"
    dimension: 1536

  # 通用配置（会被上面选中的提供者配置覆盖）
  temperature: 0.7
  max_tokens: 4000

# Embedding Configuration (已废弃，使用 llm.[provider].embedding_model)
# 保留此部分以保持向后兼容
embedding:
  provider: "auto"  # 自动使用LLM提供者的embedding
  model: "auto"
  dimension: "auto"

# Storage Configuration
storage:
  index_dir: "./graphrag/storage/index"
  cache_dir: "./graphrag/storage/cache"
  graph_db: "./graphrag/storage/graph.db"

# Data Sources
data_sources:
  - path: "./memory/long_term/*.json"
    type: "json"
    weight: 1.0
  - path: "./memory/short_term/*.json"
    type: "json"
    weight: 0.8
  - path: "./memory/relationships/*.json"
    type: "json"
    weight: 1.0
  - path: "./memory/relationships/*.md"
    type: "markdown"
    weight: 1.0
  - path: "./memory/environment/*.json"
    type: "json"
    weight: 0.9
  - path: "./memory/timeline/*.json"
    type: "json"
    weight: 1.0
  - path: "./memory/conversations/*.md"
    type: "markdown"
    weight: 0.7

# Indexing Configuration
indexing:
  chunk_size: 512
  chunk_overlap: 50
  enable_entity_extraction: true
  enable_relationship_extraction: true
  enable_temporal_tracking: true

# Query Configuration
query:
  top_k: 5
  similarity_threshold: 0.7
  enable_reranking: true
  enable_context_expansion: true

# MCP Server Configuration
mcp:
  name: "iami-graphrag"
  version: "1.0.0"
  port: 3000
